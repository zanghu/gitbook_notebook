### word2vec：源与流

**参考资料**

知乎：[机器学习：生动理解TF-IDF算法](https://zhuanlan.zhihu.com/p/31197209)

知乎：[（九）通俗易懂理解——TF-IDF与TextRank](https://zhuanlan.zhihu.com/p/41091116)


#### 1.TF-IDF 通俗易懂的解释

`TF-IDF`有两层意思，一层是"词频"（Term Frequency，缩写为`TF`），另一层是"逆文档频率"（Inverse Document Frequency，缩写为`IDF`）。

TF-IDF算法步骤

第一步，计算词频：

考虑到文章有长短之分，为了便于不同文章的比较，进行"词频"标准化：

![](/assets/recsys006_02.jpg)

第二步，计算逆文档频率：

这时，需要一个语料库（corpus），用来模拟语言的使用环境。

![](/assets/recsys006_03.jpg)

如果一个词越常见，那么分母就越大，逆文档频率就越小越接近0。分母之所以要加1，是为了避免分母为0（即所有文档都不包含该词）。log表示对得到的值取对数。

第三步，计算TF-IDF：

![](/assets/recsys006_04.jpg)

可以看到，TF-IDF与一个词在文档中的出现次数成正比，与该词在整个语言中的出现次数成反比。所以，自动提取关键词的算法就很清楚了，就是计算出文档的每个词的TF-IDF值，然后按降序排列，取排在最前面的几个词。

#### 2.TF-IDF 的数学公式化的解释

词频（Term Frequency, TF）表示关键词w在文档Di中出现的频率：

![](/assets/recsys006_05.jpg)

