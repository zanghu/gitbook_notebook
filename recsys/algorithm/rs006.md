## TF-IDF

**参考资料**

知乎：[机器学习：生动理解TF-IDF算法](https://zhuanlan.zhihu.com/p/31197209)

知乎：[（九）通俗易懂理解——TF-IDF与TextRank](https://zhuanlan.zhihu.com/p/41091116)

### 0.TF-IDF的目标

一个语料库，语料库(corpus)包含若干个文档，每个文档（document）包含若干个单词（word）

给定一个查询词`w`，要求给出每篇文档与查询词`w`的相似度。

总之，`TF-IDF`是用来度量语料库中的文档与给定单词的相似度的算法。


### 1.TF-IDF 通俗易懂的解释

`TF-IDF`有两层意思，一层是"词频"（Term Frequency，缩写为`TF`），另一层是"逆文档频率"（Inverse Document Frequency，缩写为`IDF`）。

TF-IDF算法步骤

第一步，计算词频：

考虑到文章有长短之分，为了便于不同文章的比较，进行"词频"标准化：

![](/assets/recsys006_02.jpg)

第二步，计算逆文档频率：

这时，需要一个语料库（corpus），用来模拟语言的使用环境。

![](/assets/recsys006_03.jpg)

如果一个词越常见，那么分母就越大，逆文档频率就越小越接近0。分母之所以要加1，是为了避免分母为0（即所有文档都不包含该词）。log表示对得到的值取对数。

第三步，计算TF-IDF：

![](/assets/recsys006_04.jpg)

可以看到，TF-IDF与一个词在文档中的出现次数成正比，与该词在整个语言中的出现次数成反比。所以，自动提取关键词的算法就很清楚了，就是计算出文档的每个词的TF-IDF值，然后按降序排列，取排在最前面的几个词。

### 2.TF-IDF 的数学公式化的解释

词频（Term Frequency, TF）表示关键词w在文档Di中出现的频率：

![](/assets/recsys006_05.jpg)

其中，count(w)为关键词w的出现次数，|Di|为文档Di中所有词的数量。

IDF定义如下：

![](/assets/recsys006_06.jpg)

其中，N为所有的文档总数，I(w,Di)表示文档Di是否包含关键词，若包含则为1，若不包含则为0。（分母已进行平滑处理）

关键词w在文档Di的TF-IDF值：

![](/assets/recsys006_07.jpg)

### 3.TF-IDF 的基本假设

* 假设一：语料库`c`中的文档`d`与单词`w`的相似度，正比于`w`在`d`中的词频（`TF`），反比于`w`在`c`中的逆文档频率的对数函数值。

* 假设二：文档库中文档与指定单词的相似度等于`TF`*`IDF`
