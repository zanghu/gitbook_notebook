## lightGBM: 通过 pip 安装 GPU 版本

参考资料: [安装GPU版本的最新官方说明（含pip方式）](https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-version)


参考资料: [安装GPU版本的旧版官方说明（只包含源码编译方式）](https://lightgbm.readthedocs.io/en/latest/GPU-Tutorial.html#lightgbm-gpu-tutorial)

参考资料：[最简便的lightGBM GPU支持的安装、验证方法](https://blog.csdn.net/lccever/article/details/80535058)

### 安装经验

实际安装命令（本机已经安装了`cuda 10.1`,`boost 1.67`）：

```shell
pip install lightgbm \
    --install-option=--gpu --install-option="--opencl-include-dir=/usr/local/cuda/include/" \
    --install-option="--opencl-library=/usr/local/cuda/lib64/libOpenCL.so" \
    --install-option="--boost-include-dir=/home/zanghu/ProgramFiles/software/boost/boost_1_67_0/include" \
    --install-option="--boost-librarydir=/home/zanghu/ProgramFiles/software/boost/boost_1_67_0/lib"
```

根据官方文档，可用的`--install-option`包括：

* boost-root
* boost-dir
* boost-include-dir
* boost-librarydir
* opencl-include-dir
* opencl-library

### 测试GPU

使用`HIGGS`（希格斯玻色子）数据集

下载数据

```
git clone https://github.com/guolinke/boosting_tree_benchmarks.git
cd boosting_tree_benchmarks/data
wget "https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz"
gunzip HIGGS.csv.gz
python higgs2libsvm.py
```

测试代码

```python
# coding=utf-8
#!/usr/bin/env python
import lightgbm as lgb
import time
import os

def test_gpu():
    """"""
    params = {'max_bin': 64,
    'num_leaves': 255,
    'learning_rate': 0.1,
    'tree_learner': 'serial',
    'task': 'train',
    'is_training_metric': 'false',
    'min_data_in_leaf': 1,
    'min_sum_hessian_in_leaf': 100,
    'ndcg_eval_at': [1,3,5,10],
    'sparse_threshold': 1.0,
    'device': 'gpu',
    'gpu_platform_id': 0,
    'gpu_device_id': 0}
     
     
    dtrain = lgb.Dataset('/home/zanghu/data_base/HIGGS/higgs.train')
    t0 = time.time()
    gbm = lgb.train(params, train_set=dtrain, num_boost_round=10,
              valid_sets=None, valid_names=None,
              fobj=None, feval=None, init_model=None,
              feature_name='auto', categorical_feature='auto',
              early_stopping_rounds=None, evals_result=None,
              verbose_eval=True,
              keep_training_booster=False, callbacks=None)
    t1 = time.time()
     
    print('gpu version elapse time: {}'.format(t1-t0))
     
     
    params = {'max_bin': 64,
    'num_leaves': 255,
    'learning_rate': 0.1,
    'tree_learner': 'serial',
    'task': 'train',
    'is_training_metric': 'false',
    'min_data_in_leaf': 1,
    'min_sum_hessian_in_leaf': 100,
    'ndcg_eval_at': [1,3,5,10],
    'sparse_threshold': 1.0,
    'device': 'cpu'
    }
     
    t0 = time.time()
    gbm = lgb.train(params, train_set=dtrain, num_boost_round=10,
              valid_sets=None, valid_names=None,
              fobj=None, feval=None, init_model=None,
              feature_name='auto', categorical_feature='auto',
              early_stopping_rounds=None, evals_result=None,
              verbose_eval=True,
              keep_training_booster=False, callbacks=None)
    t1 = time.time()
     
    print('cpu version elapse time: {}'.format(t1-t0))

if __name__ == '__main__':
    test_gpu()
```